{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYDgkoK8zmS6",
        "outputId": "96059738-1a0f-444a-804a-6189cecae5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (17.3 MB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 131015 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ],
      "source": [
        "!apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def get_marks(Sem):\n",
        "\n",
        "    student_academics_url = \"/Academics.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "            print('Redirected to Academics Page successfully')\n",
        "            return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    div_panel_group = soup.find('div', class_='panel-group internalMarks')\n",
        "    print('-------------------------------------------------------------------------')\n",
        "    if div_panel_group:\n",
        "        lines = (str(div_panel_group)).split('\\n')\n",
        "        subject_details = []\n",
        "        for line in lines:\n",
        "            if 'Subject Code' in line:\n",
        "                subject_details.append(line.split('</b>')[1])\n",
        "\n",
        "        for i in range(9):\n",
        "            print(subject_details[i])\n",
        "\n",
        "            marks_obtained_id = f'ContentPlaceHolder1_RepeaterPrintInternal_lblTotal_{i}'\n",
        "            marks_obtained_element = div_panel_group.find('span', id=marks_obtained_id)\n",
        "            if marks_obtained_element:\n",
        "                marks_obtained = marks_obtained_element.text.strip().split(':')[-1].strip()\n",
        "                print(\"Marks Obtained:\", marks_obtained)\n",
        "\n",
        "            max_marks_id = f'ContentPlaceHolder1_RepeaterPrintInternal_Label1_{i}'\n",
        "            max_marks_element = div_panel_group.find('span', id=max_marks_id)\n",
        "            if max_marks_element:\n",
        "                max_marks = max_marks_element.text.strip().split(':')[-1].strip()\n",
        "                print(\"Max Marks:\", max_marks)\n",
        "\n",
        "            assignment_table_id = f'ContentPlaceHolder1_RepeaterPrintInternal_pnlAssignment_{i}'\n",
        "            assignment_table_element = div_panel_group.find('div', id=assignment_table_id)\n",
        "\n",
        "            if assignment_table_element:\n",
        "                assignment_table = assignment_table_element.find('table')\n",
        "            else:\n",
        "                assignment_table = None\n",
        "\n",
        "            if assignment_table:\n",
        "                rows = assignment_table.find_all('tr')\n",
        "                print(\"Assignment Details:\")\n",
        "                for row in rows[1:]:\n",
        "                    columns = row.find_all('td')\n",
        "                    assignment_name = columns[0].text.strip()\n",
        "                    max_marks = columns[1].text.strip()\n",
        "                    marks_obtained = columns[2].text.strip()\n",
        "                    print(f\"Assignment: {assignment_name}, Max Marks: {max_marks}, Marks Obtained: {marks_obtained}\")\n",
        "\n",
        "            print('-------------------------------------------------------------------------')\n",
        "\n",
        "    else:\n",
        "        print(\"Div element with class 'panel-group internalMarks' not found in the HTML content.\")\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_username'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "get_marks(1)\n"
      ],
      "metadata": {
        "id": "agXdxAor97hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def get_marks(Sem):\n",
        "\n",
        "    student_academics_url = \"/Academics.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "            print('Redirected to Academics Page successfully')\n",
        "            return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    div_panel_group = soup.find('div', class_='panel-group internalMarks')\n",
        "\n",
        "    marks_data = []\n",
        "\n",
        "    if div_panel_group:\n",
        "        lines = str(div_panel_group).split('\\n')\n",
        "        subject_details = []\n",
        "        for line in lines:\n",
        "            if 'Subject Code' in line:\n",
        "                subject_details.append(line.split('</b>')[1])\n",
        "\n",
        "        for i in range(9):\n",
        "            marks_text = subject_details[i] + \"\\n\"\n",
        "            marks_text += \"--------------------------------\\n\"\n",
        "\n",
        "            marks_obtained_id = f'ContentPlaceHolder1_RepeaterPrintInternal_lblTotal_{i}'\n",
        "            marks_obtained_element = div_panel_group.find('span', id=marks_obtained_id)\n",
        "            if marks_obtained_element:\n",
        "                marks_obtained = marks_obtained_element.text.strip().split(':')[-1].strip()\n",
        "                marks_text += \"Marks Obtained: \" + marks_obtained + \"\\n\"\n",
        "\n",
        "            max_marks_id = f'ContentPlaceHolder1_RepeaterPrintInternal_Label1_{i}'\n",
        "            max_marks_element = div_panel_group.find('span', id=max_marks_id)\n",
        "            if max_marks_element:\n",
        "                max_marks = max_marks_element.text.strip().split(':')[-1].strip()\n",
        "                marks_text += \"Max Marks: \" + max_marks + \"\\n\"\n",
        "\n",
        "            assignment_table_id = f'ContentPlaceHolder1_RepeaterPrintInternal_pnlAssignment_{i}'\n",
        "            assignment_table_element = div_panel_group.find('div', id=assignment_table_id)\n",
        "\n",
        "            if assignment_table_element:\n",
        "                marks_text += \"Assignment Details:\\n\"\n",
        "                assignment_table = assignment_table_element.find('table')\n",
        "                rows = assignment_table.find_all('tr')\n",
        "                for row in rows[1:]:\n",
        "                    columns = row.find_all('td')\n",
        "                    assignment_name = columns[0].text.strip()\n",
        "                    max_marks = columns[1].text.strip()\n",
        "                    marks_obtained = columns[2].text.strip()\n",
        "                    marks_text += f\"Assignment: {assignment_name}, Max Marks: {max_marks}, Marks Obtained: {marks_obtained}\\n\"\n",
        "\n",
        "            marks_text += \"--------------------------------\\n\\n\"\n",
        "            marks_data.append(marks_text)\n",
        "\n",
        "    else:\n",
        "        print(\"Div element with class 'panel-group internalMarks' not found in the HTML content.\")\n",
        "\n",
        "    return marks_data\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "marks_data = get_marks(1)\n",
        "\n",
        "# Writing marks data to a text file\n",
        "with open('Marks_6_sem.txt', 'w') as file:\n",
        "    file.writelines(marks_data)\n"
      ],
      "metadata": {
        "id": "GjnqNd7UZ-Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def get_marks(Sem):\n",
        "\n",
        "    student_academics_url = \"/Academics.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "            print('Redirected to Academics Page successfully')\n",
        "            return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    table = soup.find('table', id='tblAttendancePercentage') ######\n",
        "    print(table)\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "get_marks(1)\n"
      ],
      "metadata": {
        "id": "b2jfislwvEbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def extract_attendance_details(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    table = soup.find('table', id='tblAttendancePercentage')\n",
        "\n",
        "    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
        "        columns = row.find_all('td')\n",
        "        subject_code = columns[1].get_text().strip()\n",
        "        subject = columns[2].get_text().strip()\n",
        "        year_sem_trimester = columns[3].get_text().strip()\n",
        "        total_class = columns[4].get_text().strip()\n",
        "        days_present = columns[5].get_text().strip()\n",
        "        days_absent = columns[6].get_text().strip()\n",
        "        attendance_percentage = columns[7].get_text().strip()\n",
        "\n",
        "        print(f\"Subject Code: {subject_code}\")\n",
        "        print(f\"Subject: {subject}\")\n",
        "        print(f\"Year/Semester/Trimester: {year_sem_trimester}\")\n",
        "        print(f\"Total Class: {total_class}\")\n",
        "        print(f\"Days Present: {days_present}\")\n",
        "        print(f\"Days Absent: {days_absent}\")\n",
        "        print(f\"Attendance (%): {attendance_percentage}\")\n",
        "        print(\"----------------------------------------------------\")\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "student_academics_url = \"/Academics.aspx\"\n",
        "full_academic_url = base_url + student_academics_url\n",
        "student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "else:\n",
        "    extract_attendance_details(student_academic_response.text)\n"
      ],
      "metadata": {
        "id": "4sXFmiCNAS4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def extract_attendance_details(html_content, output_file):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    table = soup.find('table', id='tblAttendancePercentage')\n",
        "\n",
        "    with open(output_file, 'w') as file:\n",
        "        for row in table.find_all('tr')[1:]:  # Skip the header row\n",
        "            columns = row.find_all('td')\n",
        "            subject_code = columns[1].get_text().strip()\n",
        "            subject = columns[2].get_text().strip()\n",
        "            year_sem_trimester = columns[3].get_text().strip()\n",
        "            total_class = columns[4].get_text().strip()\n",
        "            days_present = columns[5].get_text().strip()\n",
        "            days_absent = columns[6].get_text().strip()\n",
        "            attendance_percentage = columns[7].get_text().strip()\n",
        "\n",
        "            file.write(f\"Subject Code: {subject_code}\\n\")\n",
        "            file.write(f\"Subject: {subject}\\n\")\n",
        "            file.write(f\"Year/Semester/Trimester: {year_sem_trimester}\\n\")\n",
        "            file.write(f\"Total Class: {total_class}\\n\")\n",
        "            file.write(f\"Days Present: {days_present}\\n\")\n",
        "            file.write(f\"Days Absent: {days_absent}\\n\")\n",
        "            file.write(f\"Attendance (%): {attendance_percentage}\\n\")\n",
        "            file.write(\"----------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "output_file = 'Attendance_6_sem.txt'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "student_academics_url = \"/Academics.aspx\"\n",
        "full_academic_url = base_url + student_academics_url\n",
        "student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "if student_academic_response.status_code != 200:\n",
        "    print('Redirected to Academics Page successfully')\n",
        "else:\n",
        "    extract_attendance_details(student_academic_response.text, output_file)\n"
      ],
      "metadata": {
        "id": "1jQnUdjDBBZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "import os\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def extract_attendance_details(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    table = soup.find('table', id='tblAttendancePercentage')\n",
        "\n",
        "    attendance_details = []\n",
        "    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
        "        columns = row.find_all('td')\n",
        "        subject_code = columns[1].get_text().strip()\n",
        "        subject = columns[2].get_text().strip()\n",
        "        year_sem_trimester = columns[3].get_text().strip()\n",
        "        total_class = columns[4].get_text().strip()\n",
        "        days_present = columns[5].get_text().strip()\n",
        "        days_absent = columns[6].get_text().strip()\n",
        "        attendance_percentage = columns[7].get_text().strip()\n",
        "\n",
        "        attendance_details.append({\n",
        "            \"Subject Code\": subject_code,\n",
        "            \"Subject\": subject,\n",
        "            \"Year/Semester/Trimester\": year_sem_trimester,\n",
        "            \"Total Class\": total_class,\n",
        "            \"Days Present\": days_present,\n",
        "            \"Days Absent\": days_absent,\n",
        "            \"Attendance (%)\": attendance_percentage\n",
        "        })\n",
        "\n",
        "    return attendance_details\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "student_academics_url = \"/Academics.aspx\"\n",
        "full_academic_url = base_url + student_academics_url\n",
        "student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "if student_academic_response.status_code != 200:\n",
        "    print('Redirected to Academics Page successfully')\n",
        "else:\n",
        "    attendance_details = extract_attendance_details(student_academic_response.text)\n",
        "    with open('Attendance_6_sem.json', 'w') as file:\n",
        "        json.dump(attendance_details, file, indent=4)\n"
      ],
      "metadata": {
        "id": "NQyWQl4BYmoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def get_marks(Sem):\n",
        "\n",
        "    student_academics_url = \"/Academics.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "            print('Redirected to Academics Page successfully')\n",
        "            return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    div_panel_group = soup.find('div', class_='panel-group internalMarks')\n",
        "\n",
        "    marks_data = []\n",
        "\n",
        "    if div_panel_group:\n",
        "        lines = str(div_panel_group).split('\\n')\n",
        "        subject_details = []\n",
        "        for line in lines:\n",
        "            if 'Subject Code' in line:\n",
        "                subject_details.append(line.split('</b>')[1])\n",
        "\n",
        "        for i in range(9):\n",
        "            marks_text = subject_details[i] + \"\\n\"\n",
        "            marks_text += \"--------------------------------\\n\"\n",
        "\n",
        "            marks_obtained_id = f'ContentPlaceHolder1_RepeaterPrintInternal_lblTotal_{i}'\n",
        "            marks_obtained_element = div_panel_group.find('span', id=marks_obtained_id)\n",
        "            if marks_obtained_element:\n",
        "                marks_obtained = marks_obtained_element.text.strip().split(':')[-1].strip()\n",
        "                marks_text += \"Marks Obtained: \" + marks_obtained + \"\\n\"\n",
        "            else:\n",
        "                marks_text += \"Marks Obtained: NA\\n\"\n",
        "\n",
        "            max_marks_id = f'ContentPlaceHolder1_RepeaterPrintInternal_Label1_{i}'\n",
        "            max_marks_element = div_panel_group.find('span', id=max_marks_id)\n",
        "            if max_marks_element:\n",
        "                max_marks = max_marks_element.text.strip().split(':')[-1].strip()\n",
        "                marks_text += \"Max Marks: \" + max_marks + \"\\n\"\n",
        "            else:\n",
        "                marks_text += \"Max Marks: NA\\n\"\n",
        "\n",
        "            assignment_table_id = f'ContentPlaceHolder1_RepeaterPrintInternal_pnlAssignment_{i}'\n",
        "            assignment_table_element = div_panel_group.find('div', id=assignment_table_id)\n",
        "\n",
        "            if assignment_table_element:\n",
        "                marks_text += \"Assignment Details:\\n\"\n",
        "                assignment_table = assignment_table_element.find('table')\n",
        "                rows = assignment_table.find_all('tr')\n",
        "                for row in rows[1:]:\n",
        "                    columns = row.find_all('td')\n",
        "                    assignment_name = columns[0].text.strip()\n",
        "                    max_marks = columns[1].text.strip()\n",
        "                    marks_obtained = columns[2].text.strip()\n",
        "                    marks_text += f\"Assignment: {assignment_name}, Max Marks: {max_marks}, Marks Obtained: {marks_obtained}\\n\"\n",
        "\n",
        "            marks_text += \"--------------------------------\\n\\n\"\n",
        "            marks_data.append(marks_text)\n",
        "\n",
        "    else:\n",
        "        print(\"Div element with class 'panel-group internalMarks' not found in the HTML content.\")\n",
        "\n",
        "    return marks_data\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "marks_data = get_marks(1)\n",
        "\n",
        "# Writing marks data to a JSON file\n",
        "with open('Marks_6_sem.json', 'w') as file:\n",
        "    json.dump(marks_data, file, indent=4)\n"
      ],
      "metadata": {
        "id": "ZN3m_SSYchsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "def get_grades():\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    table = soup.find('table', id='ContentPlaceHolder1_grvGradeSheet')\n",
        "\n",
        "    if table:\n",
        "        rows = table.find_all('tr')\n",
        "\n",
        "        grades_data = []\n",
        "\n",
        "        for row in rows[1:]:\n",
        "            cells = row.find_all('td')\n",
        "            sl_no = cells[0].text.strip()\n",
        "            subject_code = cells[1].text.strip()\n",
        "            subject_name = cells[2].text.strip()\n",
        "            semester = cells[3].text.strip()\n",
        "            grade = cells[4].text.strip() if cells[4].text.strip() else 'NA'\n",
        "            credit = cells[5].text.strip()\n",
        "\n",
        "            # Create dictionary for each row\n",
        "            row_data = {\n",
        "                \"Sl No.\": sl_no,\n",
        "                \"Subject Code\": subject_code,\n",
        "                \"Subject Name\": subject_name,\n",
        "                \"Actual Semester/Year\": semester,\n",
        "                \"Grade\": grade,\n",
        "                \"Credit\": credit\n",
        "            }\n",
        "\n",
        "            grades_data.append(row_data)\n",
        "\n",
        "        # Write data to JSON file\n",
        "        with open('grades_data.json', 'w') as json_file:\n",
        "            json.dump(grades_data, json_file, indent=4)\n",
        "\n",
        "        print(\"Grades data written to grades_data.json file.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Grade sheet table not found.\")\n",
        "\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "get_grades()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEBnZ1St5p-d",
        "outputId": "5df17626-bf86-49b5-aa78-ae98ae6420b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grades data written to grades_data.json file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    elif 'System doesn\\'t recognize password.' in post_response.text:\n",
        "                        print('System doesn\\'t recognize password. (-_-)')\n",
        "                    else:\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def get_gpa():\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    gpa_div = soup.find('div', class_='col-xs-6 col-md-6')\n",
        "\n",
        "    if gpa_div:\n",
        "        gpa_span = gpa_div.find('span', id='ContentPlaceHolder1_lblGPA')\n",
        "        if gpa_span:\n",
        "            gpa = gpa_span.text.strip()\n",
        "            print(\"GPA:\", gpa)\n",
        "        else:\n",
        "            print(\"GPA not found.\")\n",
        "    else:\n",
        "        print(\"GPA div not found.\")\n",
        "\n",
        "\n",
        "def get_cgpa():\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    gpa_div = soup.find('div', class_='col-xs-6 col-md-6')\n",
        "\n",
        "    if gpa_div:\n",
        "        gpa_span = gpa_div.find('span', id='ContentPlaceHolder1_lblGPA')\n",
        "        if gpa_span:\n",
        "            gpa = gpa_span.text.strip()\n",
        "            print(\"GPA:\", gpa)\n",
        "        else:\n",
        "            print(\"GPA not found.\")\n",
        "    else:\n",
        "        print(\"GPA div not found.\")\n",
        "\n",
        "\n",
        "def get_cgpa():\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    cgpa_span = soup.find('span', id='ContentPlaceHolder1_lblCGPA')\n",
        "\n",
        "    if cgpa_span:\n",
        "        cgpa = cgpa_span.text.strip()\n",
        "        print(\"CGPA:\", cgpa)\n",
        "    else:\n",
        "        print(\"CGPA not found.\")\n",
        "\n",
        "\n",
        "def get_totalCreditsEarned():\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    credits_span = soup.find('span',id=\"ContentPlaceHolder1_LabelTotalcredit\")\n",
        "\n",
        "    if credits_span:\n",
        "        credits = credits_span.text.strip()\n",
        "        print(\"total credits earned:\", credits)\n",
        "    else:\n",
        "        print(\"credits not found.\")\n",
        "\n",
        "def get_grades():\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    table = soup.find('table', id='ContentPlaceHolder1_grvGradeSheet')\n",
        "\n",
        "    if table:\n",
        "        rows = table.find_all('tr')\n",
        "\n",
        "        grades_data = []\n",
        "\n",
        "        for row in rows[1:]:\n",
        "            cells = row.find_all('td')\n",
        "            sl_no = cells[0].text.strip()\n",
        "            subject_code = cells[1].text.strip()\n",
        "            subject_name = cells[2].text.strip()\n",
        "            semester = cells[3].text.strip()\n",
        "            grade = cells[4].text.strip() if cells[4].text.strip() else 'NA'\n",
        "            credit = cells[5].text.strip()\n",
        "\n",
        "            # Create dictionary for each row\n",
        "            row_data = {\n",
        "                \"Sl No.\": sl_no,\n",
        "                \"Subject Code\": subject_code,\n",
        "                \"Subject Name\": subject_name,\n",
        "                \"Actual Semester/Year\": semester,\n",
        "                \"Grade\": grade,\n",
        "                \"Credit\": credit\n",
        "            }\n",
        "\n",
        "            grades_data.append(row_data)\n",
        "\n",
        "        # Write data to JSON file\n",
        "        with open('grades_data.json', 'w') as json_file:\n",
        "            json.dump(grades_data, json_file, indent=4)\n",
        "\n",
        "        print(\"Grades data written to grades_data.json file.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Grade sheet table not found.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Dachu@2004'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "get_gpa()\n",
        "get_cgpa()\n",
        "get_totalCreditsEarned()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVfCnRE7Ap_p",
        "outputId": "fe63fb78-723e-4a53-ea91-526e2de6695e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System doesn't recognize password. (-_-)\n",
            "Redirected to Academics Page successfully\n",
            "Redirected to Academics Page successfully\n",
            "Redirected to Academics Page successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "import json\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "def get_gpa(base_url, headers):\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return None\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    gpa_div = soup.find('div', class_='col-xs-6 col-md-6')\n",
        "\n",
        "    if gpa_div:\n",
        "        gpa_span = gpa_div.find('span', id='ContentPlaceHolder1_lblGPA')\n",
        "        if gpa_span:\n",
        "            gpa = gpa_span.text.strip()\n",
        "            print(\"GPA:\", gpa)\n",
        "            return gpa\n",
        "        else:\n",
        "            print(\"GPA not found.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"GPA div not found.\")\n",
        "        return None\n",
        "\n",
        "def get_cgpa(base_url, headers):\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return None\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    cgpa_span = soup.find('span', id='ContentPlaceHolder1_lblCGPA')\n",
        "\n",
        "    if cgpa_span:\n",
        "        cgpa = cgpa_span.text.strip()\n",
        "        print(\"CGPA:\", cgpa)\n",
        "        return cgpa\n",
        "    else:\n",
        "        print(\"CGPA not found.\")\n",
        "        return None\n",
        "\n",
        "def get_totalCreditsEarned(base_url, headers):\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return None\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    credits_span = soup.find('span',id=\"ContentPlaceHolder1_LabelTotalcredit\")\n",
        "\n",
        "    if credits_span:\n",
        "        credits = credits_span.text.strip()\n",
        "        print(\"total credits earned:\", credits)\n",
        "        return credits\n",
        "    else:\n",
        "        print(\"credits not found.\")\n",
        "        return None\n",
        "\n",
        "def write_to_json(gpa, cgpa, total_credits_earned):\n",
        "    student_data = {\n",
        "        \"GPA\": gpa,\n",
        "        \"CGPA\": cgpa,\n",
        "        \"Total Credits Earned\": total_credits_earned\n",
        "    }\n",
        "\n",
        "    with open('gpa_cgpa_totalCreditsEarned.json', 'w') as json_file:\n",
        "        json.dump(student_data, json_file, indent=4)\n",
        "\n",
        "    print(\"Student data written to gpa_cgpa_totalCreditsEarned.json file.\")\n",
        "\n",
        "def scrape_student_data(base_url, headers, username, password):\n",
        "    login_with_captcha(base_url, headers, username, password)\n",
        "    gpa = get_gpa(base_url, headers)\n",
        "    cgpa = get_cgpa(base_url, headers)\n",
        "    total_credits_earned = get_totalCreditsEarned(base_url, headers)\n",
        "    write_to_json(gpa, cgpa, total_credits_earned)\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "scrape_student_data(base_url, headers, username, password)\n"
      ],
      "metadata": {
        "id": "7WIB3F6BHTtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "import json\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "def get_gpa(base_url, headers):\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return None\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    gpa_div = soup.find('div', class_='col-xs-6 col-md-6')\n",
        "\n",
        "    if gpa_div:\n",
        "        gpa_span = gpa_div.find('span', id='ContentPlaceHolder1_lblGPA')\n",
        "        if gpa_span:\n",
        "            gpa = gpa_span.text.strip()\n",
        "            print(\"GPA:\", gpa)\n",
        "            return gpa\n",
        "        else:\n",
        "            print(\"GPA not found.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"GPA div not found.\")\n",
        "        return None\n",
        "\n",
        "def get_cgpa(base_url, headers):\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return None\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    cgpa_span = soup.find('span', id='ContentPlaceHolder1_lblCGPA')\n",
        "\n",
        "    if cgpa_span:\n",
        "        cgpa = cgpa_span.text.strip()\n",
        "        print(\"CGPA:\", cgpa)\n",
        "        return cgpa\n",
        "    else:\n",
        "        print(\"CGPA not found.\")\n",
        "        return None\n",
        "\n",
        "def get_totalCreditsEarned(base_url, headers):\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return None\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    credits_span = soup.find('span',id=\"ContentPlaceHolder1_LabelTotalcredit\")\n",
        "\n",
        "    if credits_span:\n",
        "        credits = credits_span.text.strip()\n",
        "        print(\"total credits earned:\", credits)\n",
        "        return credits\n",
        "    else:\n",
        "        print(\"credits not found.\")\n",
        "        return None\n",
        "\n",
        "def get_grades(base_url, headers):\n",
        "    student_academics_url = \"/GradeSheet.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Redirected to Academics Page successfully')\n",
        "        return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    table = soup.find('table', id='ContentPlaceHolder1_grvGradeSheet')\n",
        "\n",
        "    if table:\n",
        "        rows = table.find_all('tr')\n",
        "\n",
        "        grades_data = []\n",
        "\n",
        "        for row in rows[1:]:\n",
        "            cells = row.find_all('td')\n",
        "            sl_no = cells[0].text.strip()\n",
        "            subject_code = cells[1].text.strip()\n",
        "            subject_name = cells[2].text.strip()\n",
        "            semester = cells[3].text.strip()\n",
        "            grade = cells[4].text.strip() if cells[4].text.strip() else 'NA'\n",
        "            credit = cells[5].text.strip()\n",
        "\n",
        "            # Create dictionary for each row\n",
        "            row_data = {\n",
        "                \"Sl No.\": sl_no,\n",
        "                \"Subject Code\": subject_code,\n",
        "                \"Subject Name\": subject_name,\n",
        "                \"Actual Semester/Year\": semester,\n",
        "                \"Grade\": grade,\n",
        "                \"Credit\": credit\n",
        "            }\n",
        "\n",
        "            grades_data.append(row_data)\n",
        "\n",
        "        # Write data to JSON file\n",
        "        with open('COMBINED_grade_sheet.json', 'w') as json_file:\n",
        "            student_data = {\n",
        "                \"GPA\": get_gpa(base_url, headers),\n",
        "                \"CGPA\": get_cgpa(base_url, headers),\n",
        "                \"Total Credits Earned\": get_totalCreditsEarned(base_url, headers),\n",
        "                \"Grades\": grades_data\n",
        "            }\n",
        "            json.dump(student_data, json_file, indent=4)\n",
        "\n",
        "        print(\"Student data written to gpa_cgpa_totalCreditsEarned_grades.json file.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Grade sheet table not found.\")\n",
        "\n",
        "def scrape_student_data(base_url, headers, username, password):\n",
        "    login_with_captcha(base_url, headers, username, password)\n",
        "    get_grades(base_url, headers)\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "scrape_student_data(base_url, headers, username, password)\n"
      ],
      "metadata": {
        "id": "P9_KmjPNLY9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def get_marks(Sem):\n",
        "\n",
        "    student_academics_url = \"/StudentProfile.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "            print('Redirected to Academics Page successfully')\n",
        "            return\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        file.write(student_academic_response.text)\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "    table = soup.find('div', class_=\"tab-pane active\")\n",
        "    print(table)\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "get_marks(1)"
      ],
      "metadata": {
        "id": "UREuQDA8iS89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "def login_with_captcha(base_url, headers, username, password):\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        captcha_img_tag = soup.find('img', id='imgCaptcha')\n",
        "\n",
        "        if captcha_img_tag:\n",
        "            captcha_img_url = base_url + \"/\" + captcha_img_tag['src']\n",
        "\n",
        "            captcha_response = requests.get(captcha_img_url, headers=headers)\n",
        "\n",
        "            if captcha_response.status_code == 200:\n",
        "                with open('captcha_image.jpeg', 'wb') as f:\n",
        "                    f.write(captcha_response.content)\n",
        "\n",
        "                img = Image.open('captcha_image.jpeg')\n",
        "                captcha_text = pytesseract.image_to_string(img)\n",
        "                captcha_text = captcha_text.strip()\n",
        "\n",
        "                os.remove('captcha_image.jpeg')\n",
        "\n",
        "                form_data = {\n",
        "                    'ScriptManager1': 'updpnl|btnLogin',\n",
        "                    '__EVENTTARGET': '',\n",
        "                    '__EVENTARGUMENT': '',\n",
        "                    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                    '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "                    'txtUserid': username,\n",
        "                    'txtpassword': password,\n",
        "                    'txtCaptcha': captcha_text,\n",
        "                    '__ASYNCPOST': 'true',\n",
        "                    'btnLogin': 'Sign in'\n",
        "                }\n",
        "\n",
        "                post_response = requests.post(base_url, data=form_data, headers=headers)\n",
        "\n",
        "                if post_response.status_code == 200:\n",
        "                    if 'Invalid Captcha' in post_response.text:\n",
        "                        print('Captcha Error')\n",
        "                    else:\n",
        "\n",
        "                        student_home_url = \"/studenthomepage.aspx\"\n",
        "                        full_student_home_url = base_url + student_home_url\n",
        "                        student_home_response = requests.get(full_student_home_url, headers=headers)\n",
        "\n",
        "                        if student_home_response.status_code != 200:\n",
        "                            print('Failed to redirect to Student Home Page')\n",
        "                            return\n",
        "\n",
        "                else:\n",
        "                    print(\"Login request failed. Status code:\", post_response.status_code)\n",
        "            else:\n",
        "                print(\"Failed to download CAPTCHA image. Status code:\", captcha_response.status_code)\n",
        "        else:\n",
        "            print(\"CAPTCHA image not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to fetch login page. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "def get_personal_details():\n",
        "    student_academics_url = \"/StudentProfile.aspx\"\n",
        "    full_academic_url = base_url + student_academics_url\n",
        "    student_academic_response = requests.get(full_academic_url, headers=headers)\n",
        "\n",
        "    if student_academic_response.status_code != 200:\n",
        "        print('Failed to fetch Student Profile Page')\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(student_academic_response.text, 'html.parser')\n",
        "\n",
        "    # Find input fields containing the required information\n",
        "    reg_no_input = soup.find('input', id='ContentPlaceHolder1_txtApplicationNumber')\n",
        "    student_name_input = soup.find('input', id='ContentPlaceHolder1_txtNameAs12MarkCard')\n",
        "    branch_input = soup.find('input', id='ContentPlaceHolder1_txtProgramBranch')\n",
        "    email_input = soup.find('input', id='ContentPlaceHolder1_txtStudentEmailID')\n",
        "    app_no_input = soup.find('input', id='ContentPlaceHolder1_txtUniversityRollNumber')\n",
        "    phone_no_input = soup.find('input', id='ContentPlaceHolder1_txtStudentMobileNumberPresent')\n",
        "    gender_input = soup.find('input', id='ContentPlaceHolder1_txtGender')\n",
        "    dob_input = soup.find('input', id='ContentPlaceHolder1_txtDOB')\n",
        "\n",
        "    # Extract values from input fields\n",
        "    reg_no = reg_no_input['value'] if reg_no_input else 'N/A'\n",
        "    student_name = student_name_input['value'] if student_name_input else 'N/A'\n",
        "    branch = branch_input['value'] if branch_input else 'N/A'\n",
        "    email = email_input['value'] if email_input else 'N/A'\n",
        "    app_no = app_no_input['value'] if app_no_input else 'N/A'\n",
        "    phone_no = phone_no_input['value'] if phone_no_input else 'N/A'\n",
        "    gender = gender_input['value'] if gender_input else 'N/A'\n",
        "    dob = dob_input['value'] if dob_input else 'N/A'\n",
        "\n",
        "    # Create dictionary for personal details\n",
        "    personal_details = {\n",
        "        \"Registration Number\": reg_no,\n",
        "        \"Student Name\": student_name,\n",
        "        \"Branch\": branch,\n",
        "        \"Email ID\": email,\n",
        "        \"Application Number\": app_no,\n",
        "        \"Phone Number\": phone_no,\n",
        "        \"Gender\": gender,\n",
        "        \"Date of Birth\": dob\n",
        "    }\n",
        "\n",
        "    # Write personal details to JSON file\n",
        "    with open('personal_details.json', 'w') as json_file:\n",
        "        json.dump(personal_details, json_file, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "base_url = \"https://slcm.manipal.edu\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
        "    'Cookie': 'ASP.NET_SessionId=junptmnf0ncgtk4wrx4qonpm',\n",
        "    'Referer': 'https://slcm.manipal.edu',\n",
        "}\n",
        "username = 'Enter_your_SLCM_username'\n",
        "password = 'Enter_your_SLCM_password'\n",
        "\n",
        "login_with_captcha(base_url, headers, username, password)\n",
        "get_personal_details()"
      ],
      "metadata": {
        "id": "vPmAACRNri1W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}